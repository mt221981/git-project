"""ArticleGenerator - Core service for generating SEO-optimized legal articles using Claude API."""

import json
import re
from typing import Dict, Any
from anthropic import Anthropic
from app.config import settings
from app.utils.json_repair import safe_parse_json
from app.services.quality_checker import QualityChecker


class ArticleGeneratorError(Exception):
    """Exception raised when article generation fails."""
    pass


class ArticleGenerator:
    """
    Core service for generating SEO-optimized articles from analyzed verdicts.

    Creates comprehensive, E-E-A-T compliant articles with:
    - Proper SEO structure and meta tags
    - Structured H2 sections
    - FAQ section with Schema.org markup
    - Common mistakes section
    - Legal disclaimers
    - All written as experienced Israeli lawyer
    """

    SYSTEM_PROMPT = """××ª×” ×¢×•×¨×š ×“×™×Ÿ ×™×©×¨××œ×™ ×× ×•×¡×” ×”××ª××—×” ×‘×›×ª×™×‘×ª ×ª×•×›×Ÿ ××©×¤×˜×™ SEO-××•×¤×˜×™××œ×™.

## ×“×¨×™×©×•×ª ×”××××¨:

### 1. ××‘× ×” ×•×ª×•×›×Ÿ:
- **××•×¨×š: 1800-2200 ××™×œ×™×** - ×§×¨×™×˜×™!
- H1: ×›×•×ª×¨×ª ×¨××©×™×ª ×¢× ××™×œ×ª ××¤×ª×—
- H2-H3: ×”×™×¨×¨×›×™×” ×‘×¨×•×¨×” (×œ×¤×—×•×ª 7 H2, 10-12 H3)
- ×¤×¡×§×” ×¤×•×ª×—×ª ×—×–×§×” ×©××¡×‘×™×¨×” ××ª ×”×¨×œ×•×•× ×˜×™×•×ª
- ×¨×§×¢ ×¢×•×‘×“×ª×™ ×©×œ ×”××§×¨×”
- × ×™×ª×•×— ×”×—×œ×˜×ª ×‘×™×ª ×”××©×¤×˜
- ×”×©×œ×›×•×ª ××¢×©×™×•×ª
- ×¡×¢×™×£ FAQ (8-10 ×©××œ×•×ª)
- ×¡×™×›×•× + ×§×¨×™××” ×œ×¤×¢×•×œ×”

### 2. E-E-A-T (×§×¨×™×˜×™ - ×™×¢×“ 85+):

**Expertise (××•××—×™×•×ª ××§×¦×•×¢×™×ª):**
- ×”×©×ª××© ×‘-10-15 ××•× ×—×™× ××©×¤×˜×™×™× ××§×¦×•×¢×™×™× ××¤×•×¨×©×™×
- ×”×¡×‘×¨ ×›×œ ××•× ×— ×‘××©×¤×˜ ×”×‘× (×“×•×’××”: "×—×•×‘×ª ×–×”×™×¨×•×ª (×”×—×•×‘×” ×”××©×¤×˜×™×ª ×œ×× ×•×¢ × ×–×§ ×œ××—×¨×™×)")
- ×”×¤×’×Ÿ ×™×“×¢ ××¢××™×§ ×‘×ª×—×•× ×”××©×¤×˜×™ ×”×¡×¤×¦×™×¤×™

**Authoritativeness (×¡××›×•×ª×™×•×ª):**
- ×¦×˜×˜ **8-10 ×¡×¢×™×¤×™ ×—×•×§** ×¡×¤×¦×™×¤×™×™× ×¢× ××¡×¤×¨×™× ××“×•×™×§×™×
  ×“×•×’××”: "×¡×¢×™×£ 35 ×œ×—×•×§ ×”× ×–×™×§×™×Ÿ ×”××–×¨×—×™×™× ×§×•×‘×¢..."
- ×”×©×ª××© ×‘×‘×™×˜×•×™×™× ×›××•: "×”×”×œ×›×” ×”×¤×¡×•×§×” ×§×•×‘×¢×ª", "×¢×œ ×¤×™ ×”×¤×¡×™×§×” ×”×¢×§×‘×™×ª"
- ××–×›×¨ ×¢×§×¨×•× ×•×ª ××©×¤×˜×™×™× ×›×œ×œ×™×™× (×œ×œ× ××¡×¤×¨×™ ×ª×™×§×™×!)
- ×”×•×¡×£ 2-3 ×”×¤× ×™×•×ª ×œnevo.co.il ××• gov.il
- ×›×ª×•×‘ ×‘×˜×•×Ÿ ××§×¦×•×¢×™ ×•×¡××›×•×ª×™

**Trustworthiness (×××™× ×•×ª):**
- ×‘×¡×¡ ×›×œ ×˜×¢× ×” ×¢×œ ×¢×•×‘×“×•×ª ××¤×¡×§ ×”×“×™×Ÿ
- ×”×•×¡×£ disclaimer ××¤×•×¨×˜ ×‘×¡×•×£: "×”××™×“×¢ ×‘××××¨ ×–×” ××‘×•×¡×¡ ×¢×œ × ×™×ª×•×— ××©×¤×˜×™ ×•××™× ×• ××”×•×•×” ×™×™×¢×•×¥ ××©×¤×˜×™. ×›×œ ××§×¨×” ×”×•× ×™×™×—×•×“×™ ×•×“×•×¨×© ×‘×—×™× ×” ×¤×¨×˜× ×™×ª ×¢×œ ×™×“×™ ×¢×•×¨×š ×“×™×Ÿ."
- ××œ ×ª××¦×™× ×¢×•×‘×“×•×ª ××• ×ª×§×“×™××™×

### 2.5 ×”× ×—×™×•×ª ×œ×¦×™×˜×•×˜×™× (×—×©×•×‘!):
**××¡×¤×¨×™ ×”×œ×™×š ×•×©××•×ª ×¤×¡×§×™ ×“×™×Ÿ:**
- âœ“ ××•×ª×¨: "×¢×œ ×¤×™ ×”×¤×¡×™×§×”", "×”×”×œ×›×” ×”×¤×¡×•×§×” ×§×•×‘×¢×ª", "×‘×¤×¡×™×§×” × ×§×‘×¢"
- âœ“ ××•×ª×¨: ×©××•×ª ×—×•×§×™× ××œ××™× - "×—×•×§ ×”× ×–×™×§×™×Ÿ ×”××–×¨×—×™×™×", "×—×•×§ ×”×‘×™×˜×•×— ×”×œ××•××™"
- âœ— ××¡×•×¨: ××¡×¤×¨×™ ×”×œ×™×š ×¡×¤×¦×™×¤×™×™× - "×¢"× 123/45", "×ª"× 456/20"
- âœ— ××¡×•×¨: ×©××•×ª ×¤×¡×§×™ ×“×™×Ÿ - "×¤×œ×•× ×™ × ' ××œ××•× ×™"

**×“×•×’××”:**
âŒ ×¨×¢: "×‘×¢"× 1234/20 ×¤×œ×•× ×™ × ' ×—×‘×¨×ª ×”×—×©××œ × ×§×‘×¢..."
âœ… ×˜×•×‘: "×‘×¤×¡×™×§×” × ×§×‘×¢ ×©××¢×‘×™×“ ×—×™×™×‘ ×‘××—×¨×™×•×ª ×§×¤×™×“×” ×¢×œ ×¤×™ ×¡×¢×™×£ 35 ×œ×—×•×§ ×”× ×–×™×§×™×Ÿ..."

### 3. SEO (×§×¨×™×˜×™ - ×™×¢×“ 85+):

**××™×œ×ª ××¤×ª×— ×¨××©×™×ª - ×—×•×‘×”:**
- ×¦×¤×™×¤×•×ª: 1.3-1.5% (×‘×“×•×§ ×•×¡×¤×•×¨!)
- ×—×•×‘×” ×‘×¤×¡×§×” ×”×¨××©×•× ×” (100 ××™×œ×™× ×¨××©×•× ×•×ª)
- ×—×•×‘×” ×‘×›×œ H2 (×œ×¤×—×•×ª 5-6 ×¤×¢××™×)
- ×—×•×‘×” ×‘-meta title ×•×‘-meta description
- ×—×•×‘×” ×‘-2-3 ×›×•×ª×¨×•×ª H3

**××™×œ×•×ª ××¤×ª×— ××©× ×™×•×ª:**
- ×›×œ ××™×œ×ª ××¤×ª×— ××©× ×™×ª: 4-6 ×”×–×›×¨×•×ª (×œ× ×¤×—×•×ª!)
- ×¤×–×¨ ×‘××•×¤×Ÿ ×˜×‘×¢×™ ×œ××•×¨×š ×”××××¨

**Meta ×ª×™×•×’×™×:**
- Meta title: 55-60 ×ª×•×•×™×, ×›×•×œ×œ ××™×œ×ª ××¤×ª×— ×‘×ª×—×™×œ×ª ×”×›×•×ª×¨×ª
- Meta description: 150-160 ×ª×•×•×™×, ×›×•×œ×œ ××™×œ×ª ××¤×ª×— + value proposition + CTA

**×§×™×©×•×¨×™×:**
- ×§×™×©×•×¨×™× ×¤× ×™××™×™×: 4-5 (×œ×“×¤×™× ×¨×œ×•×•× ×˜×™×™×)
- ×§×™×©×•×¨×™× ×—×™×¦×•× ×™×™×: 2-3 (nevo.co.il, gov.il)

### 4. ×§×¨×™××•×ª:
- ××©×¤×˜×™× ×§×¦×¨×™×: ×××•×¦×¢ 12-15 ××™×œ×™×
- ×¤×¡×§××•×ª ×§×¦×¨×•×ª: 2-3 ×©×•×¨×•×ª ××§×¡×™××•×
- ×¨×©×™××•×ª ×ª×‘×œ×™×˜×™×: 6-8 ×œ×¤×—×•×ª
- ××™×œ×•×ª ××¢×‘×¨: ×œ×¤×—×•×ª 10 ××™×œ×•×ª ××¢×‘×¨ ×©×•× ×•×ª

### 5. ××¡×•×¨ ×‘×”×—×œ×˜:
- âœ— "×œ×§×•×—×•×ª", "×× ×•", "××©×¨×“× ×•"
- âœ— ×§×™×“×•× ××›×™×¨×•×ª ×™×©×™×¨
- âœ— ×”×‘×˜×—×•×ª ×œ×ª×•×¦××•×ª
- âœ— keyword stuffing

## ×¤×•×¨××˜ ×”×—×–×¨×”:
×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“ ×¢× ×”××‘× ×” ×”×‘×:
{
  "title": "×›×•×ª×¨×ª H1",
  "meta_title": "×›×•×ª×¨×ª meta (60 ×ª×•×•×™×)",
  "meta_description": "×ª×™××•×¨ meta (150-160 ×ª×•×•×™×)",
  "content_html": "×ª×•×›×Ÿ HTML ××œ×",
  "excerpt": "×ª×§×¦×™×¨ ×§×¦×¨",
  "focus_keyword": "××™×œ×ª ××¤×ª×— ×¨××©×™×ª",
  "secondary_keywords": ["××™×œ×ª ××¤×ª×— 1", "××™×œ×ª ××¤×ª×— 2"],
  "long_tail_keywords": ["×‘×™×˜×•×™ ××¨×•×š 1", "×‘×™×˜×•×™ ××¨×•×š 2"],
  "faq_items": [{"question": "×©××œ×”", "answer": "×ª×©×•×‘×”"}],
  "common_mistakes": ["×˜×¢×•×ª 1", "×˜×¢×•×ª 2"],
  "internal_links": [],
  "external_links": ["https://nevo.co.il/..."],
  "category_primary": "× ×–×™×§×™×Ÿ",
  "categories_secondary": ["×ª××•× ×•×ª ×¢×‘×•×“×”", "×¤×™×¦×•×™×™×"],
  "tags": ["×ª×’1", "×ª×’2"],
  "featured_image_prompt": "×ª×™××•×¨ ×ª××•× ×”",
  "featured_image_alt": "alt text"
}
"""

    def __init__(self, api_key: str = None):
        """
        Initialize ArticleGenerator.

        Args:
            api_key: Anthropic API key (uses settings.ANTHROPIC_API_KEY if not provided)
        """
        self.api_key = api_key or settings.ANTHROPIC_API_KEY
        if not self.api_key or self.api_key == "your-key-here":
            raise ValueError("ANTHROPIC_API_KEY not configured. Set it in .env file.")

        self.client = Anthropic(api_key=self.api_key)

    def generate(self, verdict_data: Dict[str, Any], max_retries: int = 2, improvement_hints: str = None) -> Dict[str, Any]:
        """
        Generate SEO-optimized article from analyzed verdict data.

        Args:
            verdict_data: Dictionary containing analyzed verdict data from VerdictAnalyzer
            max_retries: Maximum number of retry attempts on failure
            improvement_hints: Optional specific improvement instructions from quality scoring

        Returns:
            Dictionary with complete article data:
            {
                "title": str,  # max 60 chars
                "meta_description": str,  # max 155 chars
                "slug": str,
                "excerpt": str,
                "focus_keyword": str,
                "secondary_keywords": List[str],  # 5-8 items
                "long_tail_keywords": List[str],  # 8-12 items
                "content_html": str,  # 1500-2500 words with full structure
                "word_count": int,
                "reading_time_minutes": int,
                "faq_items": List[Dict],  # [{question, answer}, ...]
                "common_mistakes": List[Dict],  # [{mistake, explanation}, ...]
                "category_primary": str,
                "tags": List[str],
                "featured_image_prompt": str,
                "featured_image_alt": str,
                "schema_article": Dict,  # JSON-LD
                "schema_faq": Dict  # JSON-LD
            }

        Raises:
            ArticleGeneratorError: If generation fails after all retries
        """
        if not verdict_data:
            raise ArticleGeneratorError("Verdict data cannot be empty")

        last_error = None

        for attempt in range(max_retries + 1):
            try:
                # Build prompt (with improvement hints if provided)
                user_prompt = self._build_prompt(verdict_data, improvement_hints)

                # Call Claude API
                response = self.client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=16384,  # Increased for complete article with all fields
                    temperature=0.7,  # Some creativity for natural writing
                    system=self.SYSTEM_PROMPT,
                    messages=[{
                        "role": "user",
                        "content": user_prompt
                    }]
                )

                # Extract text from response and log stop reason
                response_text = response.content[0].text
                stop_reason = response.stop_reason
                usage = response.usage
                print(f"[ArticleGenerator] API response - stop_reason: {stop_reason}, input_tokens: {usage.input_tokens}, output_tokens: {usage.output_tokens}, response_length: {len(response_text)}")

                # Parse JSON with repair logic
                result = self._parse_response(response_text)

                # Validate and enrich
                enriched_result = self._validate_and_enrich(result, verdict_data)

                # CRITICAL VALIDATION: Check word count
                word_count = enriched_result.get("word_count", 0)
                if word_count < 1800:
                    print(f"[ArticleGenerator] WARNING: Article too short - {word_count} words (minimum: 1800)")

                    # If we have retries left, try again with stronger emphasis
                    if attempt < max_retries:
                        print(f"[ArticleGenerator] Retrying with stronger word count emphasis...")
                        # Force retry with modified prompt on next iteration
                        raise ArticleGeneratorError(
                            f"Article too short: {word_count} words (minimum: 1800). Retrying with emphasis."
                        )
                    else:
                        # Last attempt failed - log warning but return result
                        print(f"[ArticleGenerator] WARNING: Final attempt produced only {word_count} words (target: 1800-2200)")

                return enriched_result

            except (ArticleGeneratorError, json.JSONDecodeError) as e:
                last_error = e
                if attempt < max_retries:
                    print(f"[ArticleGenerator] Attempt {attempt + 1} failed: {str(e)[:100]}. Retrying...")
                    continue

            except Exception as e:
                last_error = e
                if attempt < max_retries:
                    print(f"[ArticleGenerator] Attempt {attempt + 1} failed: {str(e)[:100]}. Retrying...")
                    continue

        raise ArticleGeneratorError(f"Article generation failed after {max_retries + 1} attempts: {str(last_error)}")

    def _build_prompt(self, verdict_data: Dict[str, Any], improvement_hints: str = None) -> str:
        """Build the user prompt for Claude."""
        # Extract SEO-critical fields for emphasis
        focus_keyword = verdict_data.get("focus_keyword", "")
        secondary_keywords = verdict_data.get("secondary_keywords", [])

        # Format verdict data nicely
        verdict_json = json.dumps(verdict_data, ensure_ascii=False, indent=2)

        # Build improvement hints section if provided
        improvement_section = ""
        if improvement_hints:
            improvement_section = f"""
## âš ï¸ ×—×©×•×‘ ×××•×“ - ×©×™×¤×•×¨×™× × ×“×¨×©×™×!

×”× ×™×¡×™×•×Ÿ ×”×§×•×“× ×œ× ×¢××“ ×‘×¡×˜× ×“×¨×˜ ×”××™×›×•×ª (×¦×™×•×Ÿ ××™× ×™××œ×™: 90).
**×¢×œ×™×š ×œ×©×¤×¨ ××ª ×”× ×§×•×“×•×ª ×”×‘××•×ª:**

{improvement_hints}

**×–×” ×§×¨×™×˜×™! ×”×§×¤×“ ×œ×™×™×©× ××ª ×›×œ ×”×”× ×—×™×•×ª ×œ×¢×™×œ!**

---

"""

        # Build SEO emphasis section
        seo_emphasis = ""
        if focus_keyword:
            # Generate slug suggestion from focus keyword
            slug_suggestion = focus_keyword.replace(" ", "-").replace("'", "").replace('"', "")

            seo_emphasis = f"""
## ×§×¨×™×˜×™ ×‘×™×•×ª×¨ - SEO (×¦×™×•×Ÿ ×™×¢×“: 90+):

**××™×œ×ª ×”××¤×ª×— ×”×¨××©×™×ª ×©× ×§×‘×¢×”: "{focus_keyword}"**

### ×—×•×‘×•×ª ××•×—×œ×˜×•×ª - ×œ× ×œ×¤×¡×¤×¡!

1. **×›×•×ª×¨×ª H1**: ×—×™×™×‘×ª ×œ×›×œ×•×œ "{focus_keyword}" (××§×¡×™××•× 60 ×ª×•×•×™×)

2. **Meta description**: ×—×™×™×‘×ª ×œ×›×œ×•×œ "{focus_keyword}" (120-160 ×ª×•×•×™×)

3. **×¤×¡×§×” ×¨××©×•× ×”**: ×—×™×™×‘×ª ×œ×›×œ×•×œ "{focus_keyword}" ×‘×ª×•×š 100 ×”××™×œ×™× ×”×¨××©×•× ×•×ª

4. **Slug**: ×—×™×™×‘ ×œ×›×œ×•×œ ××ª ××™×œ×ª ×”××¤×ª×— ×‘××•×ª×™×•×ª ×œ×˜×™× ×™×•×ª!
   - ×“×•×’××” × ×›×•× ×”: "{slug_suggestion}"
   - ×”×©×ª××© ×‘×ª×¢×ª×™×§ ×œ×˜×™× ×™ ×©×œ ××™×œ×ª ×”××¤×ª×—

5. **×¦×¤×™×¤×•×ª ××™×œ×•×ª ××¤×ª×— - ×§×¨×™×˜×™!**:
   - ××™×œ×ª ×”××¤×ª×— "{focus_keyword}" ×—×™×™×‘×ª ×œ×”×•×¤×™×¢ **×œ×¤×—×•×ª 15-20 ×¤×¢××™×** ×‘××××¨ ×©×œ 2000 ××™×œ×™×
   - ×–×” ×™×ª×Ÿ ×¦×¤×™×¤×•×ª ×©×œ 1.0%-1.5% ×©×”×™× ×”×¦×¤×™×¤×•×ª ×”××•×¤×˜×™××œ×™×ª
   - ×©×œ×‘ ××ª ××™×œ×ª ×”××¤×ª×— ×‘××•×¤×Ÿ ×˜×‘×¢×™ ×‘×›×•×ª×¨×•×ª H2, ×‘×¤×¡×§××•×ª, ×•×‘×ª×©×•×‘×•×ª ×œ-FAQ

6. **××™×œ×•×ª ××¤×ª×— ××©× ×™×•×ª** - ×›×œ ××—×ª ×—×™×™×‘×ª ×œ×”×•×¤×™×¢ **×œ×¤×—×•×ª 3 ×¤×¢××™×**:
   {', '.join(secondary_keywords) if secondary_keywords else '×œ× ×¡×•×¤×§×•'}

"""

        return f"""×¦×•×¨ ××××¨ ××©×¤×˜×™ SEO-××•×¤×˜×™××œ×™ ××§×¦×•×¢×™ ×¢×œ ×‘×¡×™×¡ × ×ª×•× ×™ ×¤×¡×§ ×”×“×™×Ÿ ×”×‘××™×.

{improvement_section}
## ğŸ¯ ×“×¨×™×©×•×ª ×§×¨×™×˜×™×•×ª - ×—×•×‘×” ×œ××™×œ×•×™!

### E-E-A-T (×¦×™×•×Ÿ ×™×¢×“: 85+):
- **×¦×˜×˜ 8-10 ×¡×¢×™×¤×™ ×—×•×§ ×¡×¤×¦×™×¤×™×™×** ×¢× ××¡×¤×¨×™× ××“×•×™×§×™×
- **×”×©×ª××© ×‘-10-15 ××•× ×—×™× ××©×¤×˜×™×™×** ×•×”×¡×‘×¨ ×›×œ ××—×“
- **×›×ª×•×‘ ×‘×˜×•×Ÿ ××§×¦×•×¢×™ ×•×¡××›×•×ª×™** - ×”×¤×’×Ÿ ××•××—×™×•×ª
- **×”×•×¡×£ disclaimer ××¤×•×¨×˜** ×‘×¡×•×£ ×”××××¨
- **××–×›×¨ ×¢×§×¨×•× ×•×ª ××©×¤×˜×™×™× ×›×œ×œ×™×™×** (×œ×œ× ××¡×¤×¨×™ ×ª×™×§×™×!)

### ××•×¨×š:
**1800-2200 ××™×œ×™× ×‘×“×™×•×§! ×–×• ×“×¨×™×©×” ×§×¨×™×˜×™×ª!**

### ×¤×•×¨××˜:
×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“!

{seo_emphasis}

## × ×ª×•× ×™ ×¤×¡×§ ×”×“×™×Ÿ:
```json
{verdict_json}
```

## ×¤×•×¨××˜ ×”×¤×œ×˜ ×”× ×“×¨×©:

```json
{{
  "title": "×›×•×ª×¨×ª ××•×©×›×ª ×•×›×•×œ×œ×ª ××™×œ×ª ××¤×ª×— - ××§×¡ 60 ×ª×•×•×™×",
  "meta_description": "×ª×™××•×¨ ××–××™×Ÿ ×•×ª××¦×™×ª×™ ×©×œ ×”××××¨ - 150-155 ×ª×•×•×™×",
  "slug": "koteret-maamar-be-ivrit",
  "excerpt": "×ª×§×¦×™×¨ ×§×¦×¨ ×©×œ ×”××××¨ ×‘-2-3 ××©×¤×˜×™×",

  "focus_keyword": "××™×œ×ª ××¤×ª×— ×¨××©×™×ª",
  "secondary_keywords": [
    "××™×œ×ª ××¤×ª×— 1",
    "××™×œ×ª ××¤×ª×— 2",
    "××™×œ×ª ××¤×ª×— 3",
    "××™×œ×ª ××¤×ª×— 4",
    "××™×œ×ª ××¤×ª×— 5"
  ],
  "long_tail_keywords": [
    "×‘×™×˜×•×™ ××¨×•×š 1",
    "×‘×™×˜×•×™ ××¨×•×š 2",
    "×‘×™×˜×•×™ ××¨×•×š 3",
    "×‘×™×˜×•×™ ××¨×•×š 4",
    "×‘×™×˜×•×™ ××¨×•×š 5",
    "×‘×™×˜×•×™ ××¨×•×š 6",
    "×‘×™×˜×•×™ ××¨×•×š 7",
    "×‘×™×˜×•×™ ××¨×•×š 8"
  ],

  "content_html": "<h1>×›×•×ª×¨×ª ×”××××¨</h1>\\n\\n<p>×¤×¡×§×ª ×¤×ª×™×—×” ×¨××©×•× ×”...</p>\\n\\n<p>×¤×¡×§×ª ×¤×ª×™×—×” ×©× ×™×™×”...</p>\\n\\n<h2>××” ×§×¨×”? ×”×¨×§×¢ ×”×¢×•×‘×“×ª×™</h2>\\n\\n<p>×ª×™××•×¨ ×”×¢×•×‘×“×•×ª...</p>\\n\\n<ul>\\n<li>×¢×•×‘×“×” 1</li>\\n<li>×¢×•×‘×“×” 2</li>\\n</ul>\\n\\n<h2>×”×©××œ×” ×”××©×¤×˜×™×ª</h2>\\n\\n<p>×ª×™××•×¨ ×”×©××œ×”...</p>\\n\\n<h2>××” ×§×•×‘×¢ ×”×—×•×§?</h2>\\n\\n<p>×”×¡×‘×¨ ×¢×œ ×”×—×•×§...</p>\\n\\n<p>×¡×¢×™×£ X ×œ×—×•×§ Y ×§×•×‘×¢...</p>\\n\\n<h2>×¤×¡×™×§×•×ª ×§×•×“××•×ª</h2>\\n\\n<p>×‘×¤×¡×§ ×“×™×Ÿ Z × ×§×‘×¢...</p>\\n\\n<h2>××” ×¤×¡×§ ×‘×™×ª ×”××©×¤×˜?</h2>\\n\\n<p>×‘×™×ª ×”××©×¤×˜ ×”×—×œ×™×˜...</p>\\n\\n<h2>××” ××¤×©×¨ ×œ×œ××•×“ ×‘×¤×•×¢×œ?</h2>\\n\\n<ul>\\n<li>×œ×§×— 1</li>\\n<li>×œ×§×— 2</li>\\n</ul>\\n\\n<h2>×˜×¢×•×™×•×ª × ×¤×•×¦×•×ª</h2>\\n\\n<ul>\\n<li><strong>×˜×¢×•×ª 1:</strong> ×”×¡×‘×¨</li>\\n<li><strong>×˜×¢×•×ª 2:</strong> ×”×¡×‘×¨</li>\\n</ul>\\n\\n<h2>×©××œ×•×ª ×•×ª×©×•×‘×•×ª</h2>\\n\\n<h3>×©××œ×” 1?</h3>\\n<p>×ª×©×•×‘×” ××¤×•×¨×˜×ª...</p>\\n\\n<h3>×©××œ×” 2?</h3>\\n<p>×ª×©×•×‘×” ××¤×•×¨×˜×ª...</p>\\n\\n<h2>×œ×¡×™×›×•×</h2>\\n\\n<p>×¡×™×›×•× ×”× ×§×•×“×•×ª ×”×¢×™×§×¨×™×•×ª...</p>\\n\\n<div class=\\"disclaimer\\">\\n<p><strong>×”×‘×”×¨×” ×—×©×•×‘×”:</strong> ×”××™×“×¢ ×‘××××¨ ×–×” ×”×•× ×œ××™×“×¢ ×›×œ×œ×™ ×‘×œ×‘×“ ×•××™× ×• ××”×•×•×” ×™×™×¢×•×¥ ××©×¤×˜×™. ×›×œ ××§×¨×” ×”×•× ×™×™×—×•×“×™ ×•×“×•×¨×© ×‘×—×™× ×” ×¤×¨×˜× ×™×ª. ×œ×”×ª×™×™×¢×¦×•×ª ×‘× ×•×©× ×¡×¤×¦×™×¤×™, ××•××œ×¥ ×œ×¤× ×•×ª ×œ×¢×•×¨×š ×“×™×Ÿ ××•××—×” ×‘×ª×—×•×.</p>\\n</div>",

  "word_count": 0,
  "reading_time_minutes": 0,

  "faq_items": [
    {{
      "question": "×©××œ×” 1?",
      "answer": "×ª×©×•×‘×” ××¤×•×¨×˜×ª ×•××§×¦×•×¢×™×ª ×œ×©××œ×” 1"
    }},
    {{
      "question": "×©××œ×” 2?",
      "answer": "×ª×©×•×‘×” ××¤×•×¨×˜×ª ×•××§×¦×•×¢×™×ª ×œ×©××œ×” 2"
    }}
  ],

  "common_mistakes": [
    {{
      "mistake": "×˜×¢×•×ª × ×¤×•×¦×” 1",
      "explanation": "××“×•×¢ ×–×• ×˜×¢×•×ª ×•××” ×¦×¨×™×š ×œ×¢×©×•×ª × ×›×•×Ÿ"
    }},
    {{
      "mistake": "×˜×¢×•×ª × ×¤×•×¦×” 2",
      "explanation": "××“×•×¢ ×–×• ×˜×¢×•×ª ×•××” ×¦×¨×™×š ×œ×¢×©×•×ª × ×›×•×Ÿ"
    }}
  ],

  "category_primary": "×“×™× ×™ ×¢×‘×•×“×”",
  "tags": ["×¤×™×¦×•×™×™ ×¤×™×˜×•×¨×™×", "×“×™× ×™ ×¢×‘×•×“×”", "×”×•×“×¢×” ××•×§×“××ª"],

  "featured_image_prompt": "Professional courtroom scene in Israel, judge's gavel, legal documents, modern and clean",
  "featured_image_alt": "××•×œ× ×‘×™×ª ××©×¤×˜ - ×¤×¡×§ ×“×™×Ÿ ×‘× ×•×©× ×¤×™×¦×•×™×™ ×¤×™×˜×•×¨×™×"
}}
```

## ×“×¨×™×©×•×ª ×—×•×‘×” (××¡×•×¨ ×œ×”×¤×¨!):

### ××•×¨×š - ×§×¨×™×˜×™ ×‘×™×•×ª×¨!
**×”××××¨ ×—×™×™×‘ ×œ×”×™×•×ª 1800-2200 ××™×œ×™× ×‘×“×™×•×§! ×œ× ×¤×—×•×ª ×-1800 ××™×œ×™×!**

### ×ª×•×›×Ÿ:
1. **7-8 ×›×•×ª×¨×•×ª H2** - ×›×œ H2 ×¢× 150-250 ××™×œ×™× ×ª×—×ª×™×•
2. **10-12 ×›×•×ª×¨×•×ª H3** - ×¨×•×‘×Ÿ ×‘-FAQ
3. **8-10 ×©××œ×•×ª FAQ** - ×›×œ ×©××œ×” H3 ×¢× ×ª×©×•×‘×” ××¤×•×¨×˜×ª
4. **5-6 ×˜×¢×•×™×•×ª × ×¤×•×¦×•×ª** - ×¢× ×”×¡×‘×¨×™× ××¤×•×¨×˜×™×
5. **6-8 ×¦×™×˜×•×˜×™ ×—×•×§** - ×¡×¢×™×¤×™× ××“×•×™×§×™× ×¢× ××¡×¤×¨×™×
6. **×ª×§×“×™××™×** - **×¨×§ ×× ××•×–×›×¨×™× ×‘×˜×§×¡×˜ ×”××§×•×¨!** ×× ××™×Ÿ ×ª×§×“×™××™× ×‘×˜×§×¡×˜ - ××œ ×ª××¦×™×!
7. **12+ ××•× ×—×™× ××©×¤×˜×™×™× ××§×¦×•×¢×™×™×**
8. **5-6 ×¨×©×™××•×ª** - bullet points ××• ××¡×¤×¨×™×
9. **Disclaimer ×—×–×§** - ×‘×¡×•×£ ×”××××¨
10. **×¦×¤×™×¤×•×ª ××™×œ×•×ª ××¤×ª×—: 1.0-1.2%**

### ×¡×’× ×•×Ÿ (×“×¨×™×©×•×ª ××—×™×™×‘×•×ª):
1. ×›×ª×•×‘ ×›×¢×•×¨×š ×“×™×Ÿ ×™×©×¨××œ×™ ×× ×•×¡×” ×¢× × ×™×¡×™×•×Ÿ ×©×œ ×©× ×™× ×¨×‘×•×ª
2. ×”×¡×‘×¨ ×‘××•× ×—×™× ×¤×©×•×˜×™× ××š ×”×©×ª××© ×‘××™× ×•×—×™× ××©×¤×˜×™×™× ××§×¦×•×¢×™×™×
3. ×ª×Ÿ ×“×•×’×××•×ª ××¢×©×™×•×ª ××—×™×™ ×”×™×•××™×•×
4. **××©×¤×˜×™× ×§×¦×¨×™×**: 15-18 ××™×œ×™× ×××•×¦×¢ (×œ× ×™×•×ª×¨ ×-20!)
5. **××™×œ×•×ª ××¢×‘×¨**: ×œ×¤×—×•×ª 10-12 ××™×œ×•×ª ××¢×‘×¨ (×œ×›×Ÿ, ×‘× ×•×¡×£, ×××™×“×š, ×•×›×•')
6. **×¤×¡×§××•×ª ×§×¦×¨×•×ª**: 2-3 ×©×•×¨×•×ª ××§×¡×™××•×
7. ××œ ×ª×‘×˜×™×— ×ª×•×¦××•×ª
8. ××œ ×ª×™×ª×Ÿ ×™×™×¢×•×¥ ×¡×¤×¦×™×¤×™

### SEO (×“×¨×™×©×•×ª ××“×•×™×§×•×ª):
1. **×›×•×ª×¨×ª H1**: 50-60 ×ª×•×•×™×, ×—×•×‘×” ×œ×”×›×™×œ ××ª ××™×œ×ª ×”××¤×ª×— ×”×¨××©×™×ª
2. **Meta description**: 150-155 ×ª×•×•×™×, ×›×•×œ×œ×ª ××™×œ×ª ××¤×ª×— ×¨××©×™×ª
3. **××™×œ×ª ××¤×ª×— ×‘×¤×¡×§×” ×”×¨××©×•× ×”**: ×—×™×™×‘ ×œ×”×–×›×™×¨ ××ª ××™×œ×ª ×”××¤×ª×— ×”×¨××©×™×ª ×‘×¤×¡×§×” ×”×¨××©×•× ×”!
4. **×¦×¤×™×¤×•×ª ××™×œ×•×ª ××¤×ª×— ×¨××©×™×ª**: 1.0-1.2% ×‘×“×™×•×§ (×—×©×‘ ×•×”×ª××!)
5. **××™×œ×•×ª ××¤×ª×— ××©× ×™×•×ª**: ×©×™××•×© ×‘-100% ××”××™×œ×•×ª ×”××©× ×™×•×ª ×œ×¤×—×•×ª ×¤×¢××™×™× ×›×œ ××—×ª
6. **Slug ×‘×¢×‘×¨×™×ª ×‘××•×ª×™×•×ª ×œ×˜×™× ×™×•×ª**: × ×§×™ ×•×§×¨×™×
7. **×§×™×©×•×¨×™× ×¤× ×™××™×™×**: 3-5 ×§×™×©×•×¨×™× ×œ××××¨×™× ××—×¨×™× (×“×•×’××”: <a href="/× ×–×™×§×™×Ÿ">× ×–×™×§×™×Ÿ</a>)
8. **×§×™×©×•×¨×™× ×—×™×¦×•× ×™×™×**: 2-3 ×§×™×©×•×¨×™× ×œ××ª×¨×™× ×××™× ×™× ×›××• https://www.nevo.co.il
9. **×©×™×œ×•×‘ ×˜×‘×¢×™**: ××œ ×ª×¢×©×” keyword stuffing

### ××™×›×•×ª (×§×¨×™×˜×¨×™×•× ×™× ××—××™×¨×™×):
1. **××¡×•×¨ keyword stuffing** - ×©×™××•×© ×˜×‘×¢×™ ×‘×œ×‘×“
2. **×¦×™×˜×•×˜×™× ×§×¦×¨×™×** - ××§×¡×™××•× 20 ××™×œ×™×
3. **××¡×•×¨ ××™×“×¢ ×›×•×–×‘** - ×¨×§ ××™×“×¢ ××‘×•×¡×¡ ×¢×œ × ×ª×•× ×™ ×¤×¡×§ ×”×“×™×Ÿ
   **××¡×•×¨ ×œ×”××¦×™× ×ª×§×“×™××™× ××• ××¡×¤×¨×™ ×ª×™×§×™× ×©×œ× ××•×¤×™×¢×™× ×‘×˜×§×¡×˜ ×”××§×•×¨!**
4. **××¡×•×¨ ×”×‘×˜×—×•×ª** - ××œ ×ª×‘×˜×™×— ×ª×•×¦××•×ª
5. **×ª×•×›×Ÿ ××§×™×£ ×•××¢××™×§** - ×›×œ ×¡×¢×™×£ ×¦×¨×™×š ×œ×”×™×•×ª ××¤×•×¨×˜ ×•××§×¦×•×¢×™
6. **×“×™×•×§ ××©×¤×˜×™ ××•×—×œ×˜** - ×›×œ ×¡×¢×™×£, ×—×•×§ ×•×ª×§×“×™× ×¦×¨×™×›×™× ×œ×”×™×•×ª × ×›×•× ×™×

### ×‘×“×™×§×ª ××™×›×•×ª ×œ×¤× ×™ ×”×’×©×” (×—×•×‘×”!):
**×§×¨×™×˜×™ ×‘×™×•×ª×¨: ×¡×¤×•×¨ ××™×œ×™× - ×—×™×™×‘ ×œ×”×™×•×ª ×œ×¤×—×•×ª 1800 ××™×œ×™×!**
- ×¡×¤×•×¨ H2: 7-8
- ×¡×¤×•×¨ H3: 10-12
- ×¡×¤×•×¨ ×¦×™×˜×•×˜×™ ×—×•×§: ×œ×¤×—×•×ª 6-8
- ×¡×¤×•×¨ ×ª×§×“×™××™×: ×¨×§ ×ª×§×“×™××™× ×©××•×–×›×¨×™× ×‘×˜×§×¡×˜ ×”××§×•×¨ (0 ×× ××™×Ÿ)
- ×¡×¤×•×¨ FAQ: 8-10
- ×¡×¤×•×¨ ×˜×¢×•×™×•×ª × ×¤×•×¦×•×ª: 5-6
- ×‘×“×•×§ ×¦×¤×™×¤×•×ª ××™×œ×ª ××¤×ª×—: 1.0-1.2%
- ×‘×“×•×§ ××•×¨×š ××©×¤×˜×™×: ×××•×¦×¢ 15-18 ××™×œ×™×
- ×‘×“×•×§ ××™×œ×•×ª ××¢×‘×¨: ×œ×¤×—×•×ª 10-12
- **×‘×“×•×§ ×©××™×œ×ª ×”××¤×ª×— ××•×¤×™×¢×” ×‘×¤×¡×§×” ×”×¨××©×•× ×”!**
- **×‘×“×•×§ ×©×™×© 3-5 ×§×™×©×•×¨×™× ×¤× ×™××™×™×!**
- **×‘×“×•×§ ×©×™×© 2-3 ×§×™×©×•×¨×™× ×—×™×¦×•× ×™×™×!**

**×–×›×•×¨: ×”××××¨ ×—×™×™×‘ ×œ×”×™×•×ª 1800-2200 ××™×œ×™×! ×–×• ×”×“×¨×™×©×” ×”×—×©×•×‘×” ×‘×™×•×ª×¨!**

**×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“! ××œ ×ª×©×›×— ×©×•× ×©×“×”!**"""

    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """Parse Claude's JSON response with robust repair logic."""
        result = safe_parse_json(response_text)

        if result is None:
            # Log the problematic response for debugging
            print(f"[ArticleGenerator] Failed to parse JSON. First 500 chars: {response_text[:500]}")
            raise ArticleGeneratorError(
                "Failed to parse Claude response as JSON after repair attempts"
            )

        return result

    def _validate_and_enrich(self, result: Dict[str, Any], verdict_data: Dict[str, Any]) -> Dict[str, Any]:
        """Validate and enrich the article data."""
        # Calculate word count from HTML
        if "content_html" in result:
            text = re.sub(r'<[^>]+>', '', result["content_html"])
            result["word_count"] = len(text.split())
            result["reading_time_minutes"] = max(1, result["word_count"] // 200)

        # Generate Schema.org JSON-LD
        result["schema_article"] = self._generate_article_schema(result, verdict_data)
        result["schema_faq"] = self._generate_faq_schema(result.get("faq_items", []))

        # Ensure all required fields
        required_fields = {
            "title": "",
            "meta_description": "",
            "slug": "",
            "excerpt": "",
            "focus_keyword": "",
            "secondary_keywords": [],
            "long_tail_keywords": [],
            "content_html": "",
            "word_count": 0,
            "reading_time_minutes": 0,
            "faq_items": [],
            "common_mistakes": [],
            "category_primary": verdict_data.get("legal_area", "××©×¤×˜×™"),
            "tags": [],
            "featured_image_prompt": "",
            "featured_image_alt": ""
        }

        for field, default in required_fields.items():
            if field not in result:
                result[field] = default

        return result

    def _generate_article_schema(self, article: Dict[str, Any], verdict_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate Schema.org Article JSON-LD."""
        return {
            "@context": "https://schema.org",
            "@type": "Article",
            "headline": article.get("title", ""),
            "description": article.get("meta_description", ""),
            "author": {
                "@type": "Organization",
                "name": "××¢×¨×›×ª ×ª×•×›×Ÿ ××©×¤×˜×™"
            },
            "datePublished": verdict_data.get("verdict_date", ""),
            "articleBody": re.sub(r'<[^>]+>', '', article.get("content_html", "")),
            "wordCount": article.get("word_count", 0),
            "inLanguage": "he",
            "about": {
                "@type": "Thing",
                "name": verdict_data.get("legal_area", "")
            }
        }

    def _generate_faq_schema(self, faq_items: list) -> Dict[str, Any]:
        """Generate Schema.org FAQPage JSON-LD."""
        if not faq_items:
            return {}

        return {
            "@context": "https://schema.org",
            "@type": "FAQPage",
            "mainEntity": [
                {
                    "@type": "Question",
                    "name": item.get("question", ""),
                    "acceptedAnswer": {
                        "@type": "Answer",
                        "text": item.get("answer", "")
                    }
                }
                for item in faq_items
            ]
        }

    def calculate_scores(self, article_content: Dict[str, Any]) -> Dict[str, Any]:
        """
        Calculate quality scores for an article using QualityChecker.

        Args:
            article_content: Article content dictionary

        Returns:
            Dictionary with quality scores:
            {
                "content_score": int,
                "seo_score": int,
                "readability_score": int,
                "eeat_score": int,
                "overall_score": int,
                "quality_issues": list[str]
            }
        """
        try:
            # Log what we're receiving
            print(f"[ArticleGenerator] calculate_scores called with keys: {list(article_content.keys())}")
            print(f"[ArticleGenerator] Has content_html: {'content_html' in article_content}")
            print(f"[ArticleGenerator] Has word_count: {'word_count' in article_content}")
            print(f"[ArticleGenerator] Has title: {'title' in article_content}")
            print(f"[ArticleGenerator] Has focus_keyword: {'focus_keyword' in article_content}")

            checker = QualityChecker()
            report = checker.check_all(article_content)

            print(f"[ArticleGenerator] QualityChecker returned scores:")
            print(f"  Content: {report.content_score}/100")
            print(f"  SEO: {report.seo_score}/100")
            print(f"  Readability: {report.readability_score}/100")
            print(f"  E-E-A-T: {report.eeat_score}/100")
            print(f"  Overall: {report.overall_score}/100")

            # Convert string issues to dict format for Pydantic schema compatibility
            quality_issues = []
            for issue in report.critical_issues:
                quality_issues.append({"type": "critical", "message": issue})
            for issue in report.warnings:
                quality_issues.append({"type": "warning", "message": issue})

            return {
                "content_score": report.content_score,
                "seo_score": report.seo_score,
                "readability_score": report.readability_score,
                "eeat_score": report.eeat_score,
                "overall_score": report.overall_score,
                "quality_issues": quality_issues
            }

        except Exception as e:
            # Log full traceback for debugging
            import traceback
            print(f"[ArticleGenerator] EXCEPTION in calculate_scores:")
            print(traceback.format_exc())

            # Return default scores if calculation fails
            return {
                "content_score": 70,
                "seo_score": 70,
                "readability_score": 70,
                "eeat_score": 70,
                "overall_score": 70,
                "quality_issues": [{"type": "error", "message": f"Failed to calculate scores: {str(e)}"}]
            }
